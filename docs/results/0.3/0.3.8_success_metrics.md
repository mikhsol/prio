# Task 0.3.8: Core Success Metrics

**Owner**: Product Manager  
**Duration**: 1h  
**Status**: Completed  
**Date**: February 3, 2026

---

## Overview

This document defines the 5 core success metrics for Jeeves MVP. These metrics will guide product decisions, measure success, and serve as leading indicators for product-market fit.

---

## Metric Selection Criteria

Metrics were selected based on:

1. **Actionable**: Team can influence through product decisions
2. **Measurable**: Can be tracked with available tools
3. **Relevant**: Connects to business outcomes
4. **Time-bound**: Clear measurement windows
5. **Leading/Lagging Balance**: Mix of predictive and outcome metrics

---

## The 5 Core Success Metrics

### 1. Daily Active Users (DAU)

**Definition**: Unique users who open the app and complete at least one meaningful action per day.

**Meaningful Actions**:
- Create or complete a task
- View daily briefing
- Check goal progress
- Record meeting notes

**Why This Metric**:
- Direct measure of product engagement
- Leading indicator for retention and revenue
- Drives habit formation (core product strategy)

**Targets**:

| Timeframe | Target | Rationale |
|-----------|--------|-----------|
| Launch Week | 1,000 DAU | 10% of 10K downloads |
| Month 1 | 2,000 DAU | 20% of cumulative downloads |
| Month 3 | 10,000 DAU | With 50K downloads |
| Month 6 | 25,000 DAU | Sustainable growth |

**Measurement**:
- Track via Firebase Analytics
- Daily dashboard update
- Segment by persona (inferred from behavior)

**Alert Thresholds**:
- ðŸŸ¢ Green: DAU growth â‰¥5%/week
- ðŸŸ¡ Yellow: DAU flat (Â±5%)
- ðŸ”´ Red: DAU decline >5%

---

### 2. Day 7 Retention (D7)

**Definition**: Percentage of users who return to the app on day 7 after first install.

**Why This Metric**:
- Measures product stickiness
- 7 days = habit formation threshold
- Industry standard for comparison
- Early warning for product-market fit issues

**Targets**:

| Timeframe | Target | Benchmark |
|-----------|--------|-----------|
| Beta | 30% | Testing baseline |
| Launch | 35% | Productivity app average |
| Month 3 | 40% | Top quartile productivity apps |
| Month 6 | 45% | Best-in-class |

**Retention Cohort Expectations**:

| Day | Target | Industry Benchmark |
|-----|--------|-------------------|
| D1 | 50% | 40-50% |
| D3 | 40% | 30-35% |
| D7 | 35% | 20-25% |
| D14 | 28% | 15-18% |
| D30 | 20% | 10-12% |

**Measurement**:
- Firebase cohort analysis
- Weekly cohort reports
- Segment by acquisition source

**Alert Thresholds**:
- ðŸŸ¢ Green: D7 â‰¥35%
- ðŸŸ¡ Yellow: D7 28-34%
- ðŸ”´ Red: D7 <28%

---

### 3. Task Completion Rate

**Definition**: Percentage of tasks created that are completed within their deadline (or within 7 days if no deadline).

**Why This Metric**:
- Measures core value delivery
- Users who complete tasks see Jeeves as valuable
- Low completion = prioritization not working
- Connects engagement to outcomes

**Calculation**:
```
Task Completion Rate = (Tasks Completed / Tasks Created) Ã— 100

Measured over rolling 7-day windows
Exclude tasks deleted within 1 hour (accidental creation)
```

**Targets**:

| Timeframe | Target | Rationale |
|-----------|--------|-----------|
| Beta | 50% | Baseline discovery |
| Launch | 55% | Minimum viable value |
| Month 3 | 65% | AI prioritization helping |
| Month 6 | 70% | Optimized experience |

**Segmented Targets**:

| Task Type | Target | Rationale |
|-----------|--------|-----------|
| Q1 (Do Now) | 85% | Urgent tasks should complete |
| Q2 (Schedule) | 60% | Important but less urgent |
| Q3 (Delegate) | 40% | User may not do themselves |
| Q4 (Consider) | 30% | Often appropriately dropped |

**Measurement**:
- Room database queries
- Daily aggregation
- Segment by quadrant

**Alert Thresholds**:
- ðŸŸ¢ Green: Overall â‰¥60%, Q1 â‰¥80%
- ðŸŸ¡ Yellow: Overall 50-59%, Q1 70-79%
- ðŸ”´ Red: Overall <50%, Q1 <70%

---

### 4. AI Classification Accuracy

**Definition**: Percentage of AI-assigned Eisenhower quadrants that users do NOT override.

**Why This Metric**:
- Measures core AI value delivery
- High accuracy = users trust AI
- Low accuracy = product failure
- Guides model improvement priorities

**Calculation**:
```
AI Accuracy = ((Tasks Classified - User Overrides) / Tasks Classified) Ã— 100

Exclude tasks completed within 1 minute of creation (no time to review)
```

**Targets**:

| Timeframe | Target | Rationale |
|-----------|--------|-----------|
| Beta | 75% | Baseline from testing |
| Launch | 80% | Minimum viable accuracy |
| Month 3 | 85% | With user feedback integration |
| Month 6 | 90% | Personalized model improvements |

**Accuracy by Quadrant**:

| Quadrant | Target | Priority |
|----------|--------|----------|
| Q1 (Do Now) | 85% | Critical - don't miss urgent items |
| Q2 (Schedule) | 80% | Important for long-term value |
| Q3 (Delegate) | 75% | Less critical |
| Q4 (Consider) | 70% | Users often re-classify |

**Measurement**:
- Track all classifications and overrides
- Store original and final classifications
- Daily accuracy calculation
- Pattern analysis on overrides

**Alert Thresholds**:
- ðŸŸ¢ Green: Accuracy â‰¥80%
- ðŸŸ¡ Yellow: Accuracy 70-79%
- ðŸ”´ Red: Accuracy <70%

**Improvement Actions**:
- Analyze override patterns
- Update rule-based fallbacks
- Collect feedback for model fine-tuning
- A/B test prompt variations

---

### 5. Crash-Free Users Rate

**Definition**: Percentage of users who experience zero app crashes in a given period.

**Why This Metric**:
- Quality is table stakes for productivity apps
- Crashes destroy trust and retention
- On-device AI adds crash risk
- Required for good app store ratings

**Calculation**:
```
Crash-Free Rate = (Users Without Crashes / Total Users) Ã— 100

Measured over 7-day rolling window
```

**Targets**:

| Timeframe | Target | Industry Standard |
|-----------|--------|-------------------|
| Beta | 95% | Testing phase |
| Launch | 99% | Minimum for launch |
| Month 1 | 99.5% | Quality bar |
| Month 3+ | 99.9% | Best-in-class |

**Related Metrics**:

| Metric | Target |
|--------|--------|
| ANR Rate | <0.1% |
| Startup Crash Rate | <0.5% |
| AI Inference Crash Rate | <0.1% |

**Measurement**:
- Firebase Crashlytics
- Real-time monitoring
- Per-device-model tracking (LLM compatibility)

**Alert Thresholds**:
- ðŸŸ¢ Green: Crash-free â‰¥99%
- ðŸŸ¡ Yellow: Crash-free 97-98.9%
- ðŸ”´ Red: Crash-free <97%

**Response Protocol**:
- <99%: P1 - Investigate within 4 hours
- <97%: P0 - Hotfix within 24 hours
- <95%: Critical - Consider rollback

---

## Metrics Dashboard

### Daily View

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     JEEVES METRICS DASHBOARD                             â”‚
â”‚                        February 3, 2026                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚      DAU       â”‚  â”‚  D7 Retention  â”‚  â”‚ Task Complete  â”‚             â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚                â”‚             â”‚
â”‚  â”‚    2,341       â”‚  â”‚     38%        â”‚  â”‚     62%        â”‚             â”‚
â”‚  â”‚   â–² +5.2%      â”‚  â”‚   â–² +2pp       â”‚  â”‚   â–² +3pp       â”‚             â”‚
â”‚  â”‚   ðŸŸ¢ On Track  â”‚  â”‚   ðŸŸ¢ On Track  â”‚  â”‚   ðŸŸ¢ On Track  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚  â”‚  AI Accuracy   â”‚  â”‚  Crash-Free    â”‚                                 â”‚
â”‚  â”‚                â”‚  â”‚                â”‚                                 â”‚
â”‚  â”‚     83%        â”‚  â”‚    99.4%       â”‚                                 â”‚
â”‚  â”‚   â–² +1pp       â”‚  â”‚   â–¼ -0.1pp     â”‚                                 â”‚
â”‚  â”‚   ðŸŸ¢ On Track  â”‚  â”‚   ðŸŸ¢ On Track  â”‚                                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                                                                          â”‚
â”‚  TRENDS (7 day)                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ DAU:  â–â–‚â–ƒâ–ƒâ–„â–…â–†                                                 â”‚       â”‚
â”‚  â”‚ D7:   â–ƒâ–ƒâ–„â–„â–„â–…â–…                                                 â”‚       â”‚
â”‚  â”‚ Task: â–„â–„â–„â–…â–…â–…â–†                                                 â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Weekly Report Template

```markdown
## Jeeves Weekly Metrics Report
Week of: [Date]

### Key Metrics Summary
| Metric | This Week | Last Week | Target | Status |
|--------|-----------|-----------|--------|--------|
| DAU | X | Y | Z | ðŸŸ¢/ðŸŸ¡/ðŸ”´ |
| D7 Retention | X% | Y% | 35% | ðŸŸ¢/ðŸŸ¡/ðŸ”´ |
| Task Completion | X% | Y% | 60% | ðŸŸ¢/ðŸŸ¡/ðŸ”´ |
| AI Accuracy | X% | Y% | 80% | ðŸŸ¢/ðŸŸ¡/ðŸ”´ |
| Crash-Free | X% | Y% | 99% | ðŸŸ¢/ðŸŸ¡/ðŸ”´ |

### Insights
1. [Key insight 1]
2. [Key insight 2]
3. [Key insight 3]

### Actions
- [ ] Action item based on metrics
```

---

## Metric Relationships

Understanding how metrics connect:

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   DOWNLOADS     â”‚
                         â”‚   (Acquisition) â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚      DAU        â”‚
                         â”‚   (Engagement)  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
                                  â”‚                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
              â”‚                   â”‚                   â”‚     â”‚
              â–¼                   â–¼                   â–¼     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  AI Accuracy    â”‚ â”‚ Task Completion â”‚ â”‚  Crash-Free     â”‚
     â”‚  (AI Value)     â”‚ â”‚ (Core Value)    â”‚ â”‚  (Quality)      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                   â”‚                   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  D7 RETENTION   â”‚
                         â”‚  (Stickiness)   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   CONVERSION    â”‚
                         â”‚   (Revenue)     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Relationships**:
- High AI Accuracy â†’ Higher Task Completion â†’ Better D7 Retention
- Crashes â†’ Lower Retention â†’ Lower DAU
- High DAU Ã— High Retention = Sustainable Growth

---

## North Star Metric

While all 5 metrics are important, the **North Star Metric** that best captures overall product success is:

### **Weekly Active Users Completing â‰¥1 Important Task**

**Definition**: Unique users per week who complete at least one Q1 or Q2 task.

**Why This is the North Star**:
1. Captures engagement (weekly usage)
2. Captures core value (AI prioritization works)
3. Captures action (not just passive usage)
4. Aligns all teams (product, engineering, design)

**Target**: 70% of WAU complete an important task

---

## Implementation Plan

### Phase 1: Pre-Launch (Week -2)
- [ ] Firebase Analytics integration complete
- [ ] Firebase Crashlytics integration complete
- [ ] Event tracking implemented for all metrics
- [ ] Dashboard prototype created

### Phase 2: Beta (Weeks 14-16)
- [ ] Baseline all metrics with beta users
- [ ] Validate tracking accuracy
- [ ] Establish alert thresholds
- [ ] Train team on dashboard usage

### Phase 3: Launch (Week 16+)
- [ ] Daily metric monitoring
- [ ] Weekly metric reviews
- [ ] Monthly deep-dives
- [ ] Quarterly target adjustments

---

## Appendix: Event Tracking Specification

### Required Events

| Event | Parameters | Metric |
|-------|------------|--------|
| `app_open` | `user_id`, `session_id`, `timestamp` | DAU |
| `task_created` | `task_id`, `quadrant`, `has_deadline` | Task metrics |
| `task_completed` | `task_id`, `quadrant`, `time_to_complete` | Task Completion |
| `ai_classification` | `task_id`, `quadrant`, `confidence` | AI Accuracy |
| `ai_override` | `task_id`, `original_quadrant`, `new_quadrant` | AI Accuracy |
| `briefing_viewed` | `briefing_type`, `tasks_shown` | Engagement |
| `goal_created` | `goal_id`, `category` | Goals metrics |
| `crash` | `crash_id`, `stack_trace`, `device_info` | Crash-Free |

### Privacy Compliance
- No PII in analytics
- User IDs are anonymous device IDs
- Opt-out option in settings
- Compliant with GDPR/CCPA

---

*Document Owner: Product Manager*  
*Last Updated: February 3, 2026*
